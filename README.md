# ðŸ§  Mental Health Chatbot

## ðŸ—‚ï¸ Overview  
A **web-based AI assistant** that provides mental health resources by analyzing multiple knowledge sources (**JSON/PDF**) using **LangChain** and **ChromaDB** vector storage.

---

## ðŸŒŸ Core Features  
- âœ… **Multi-source knowledge integration**  
  â€¢ Supports **2 JSON formats + PDF**

- ðŸ’¬ **Conversational web interface**  
  â€¢ Clean and formatted AI responses

- ðŸ“š **Source attribution**  
  â€¢ Clearly shows the **origin** of each response

- ðŸ’¾ **Persistent memory**  
  â€¢ Stores embeddings and chat history using **ChromaDB**


---

## âš¡ Quick Start

### ðŸ“¦ Install dependencies  
```bash
pip install -r requirements.txt
```

## Launch server
```
python deployment.py
```
### âž¡ï¸ Access at: http://localhost:8000




## Project Guide Map

## ðŸ“Œ Features

- âœ… JSON intent and PDF document ingestion
- âœ… Chunking and embedding with HuggingFace
- âœ… Context-aware Retrieval QA using LangChain
- âœ… FastAPI backend with HTML chat interface
- âœ… Persisted vector store using Chroma
- âœ… Pluggable LLM backend (uses `llama3-70b-8192` via Groq)
- âœ… Source document traceability

---
### 1. Project Definition & Goal
- Build an LLM-powered mental health chatbot.
- Use context from structured intents and PDFs.
- Serve a clear, empathetic answer through a web interface.

### 2. Data Acquisition & Exploration
- ðŸ“ JSON files (`intents.json`) with Q&A patterns.
- ðŸ“„ PDF files (`sample_data/`) as extra knowledge.
- Documents split into chunks for vector storage.
- Exploratory: simple loading, type checks, error handling.

### 3. Data Preprocessing
- Missing/invalid formats handled in loading loop.
- Text split using `RecursiveCharacterTextSplitter`.
- Embedding generated using `HuggingFaceBgeEmbeddings`.
- Stored in a persistent `Chroma` vector database.

### 4. Model Selection & Training
- **LLM Used:** `llama3-70b-8192` via `ChatGroq`.
- Retrieval with `LangChain RetrievalQA`.
- No model training â€” context passed directly to model for zero-shot answers.


### 5. Interpretation & Communication
- Answers returned from `/chat` endpoint with source metadata.
- Web interface built using Jinja2 + HTML.
- Answers clearly tagged with source (PDF / JSON).

### 6. Deployment
- FastAPI + `uvicorn` server.
- Auto port discovery for local deployment.
- Frontend rendered at `/` using `chat.html`.

---

## ðŸ’» Tech Stack

| Component         | Tool / Library                                |
|------------------|------------------------------------------------|
| Backend API       | FastAPI                                        |
| Vector DB         | Chroma                                         |
| Embeddings        | HuggingFace (`sentence-transformers`)         |
| LLM               | ChatGroq (`llama3-70b-8192`)                   |
| Text Splitting    | LangChain `RecursiveCharacterTextSplitter`    |
| PDF Loader        | `PyPDFLoader`                                  |
| Templating        | Jinja2                                         |
| Deployment        | `uvicorn` with dynamic port handling          |

---

## ðŸ§  Component Breakdown

| Component                              | Explanation                                                                                              |
|----------------------------------------|----------------------------------------------------------------------------------------------------------|
| **Backend API â€“ FastAPI**              | A modern Python web framework used to build and serve your chatbotâ€™s API. Fast and easy to use.         |
| **Vector DB â€“ Chroma**                 | Stores text data for semantic search. Handles embeddings and fast document retrieval.                   |
| **Embeddings â€“ HuggingFace**           | Uses `sentence-transformers` to convert text into vectors capturing semantic meaning.                   |
| **LLM â€“ ChatGroq (llama3-70b-8192)**   | A large language model running on Groq hardware for fast and accurate response generation.              |
| **Text Splitting â€“ LangChain**         | `RecursiveCharacterTextSplitter` splits long texts into chunks while preserving context.                |
| **PDF Loader â€“ PyPDFLoader**           | Loads and parses content from PDF files to prepare for embedding and search.                            |
| **Templating â€“ Jinja2**                | Python templating engine for rendering dynamic HTML or structured responses.                            |
| **Deployment â€“ uvicorn**               | Runs the FastAPI app using an ASGI server with dynamic port support, ideal for scalable deployments.    |



# ðŸ” What This Code Does (in Simple Terms)

âœ… **Loads data** from JSON (intents) and PDF files.

âœ… **Converts them into documents** with metadata.

âœ… **Splits the documents** into smaller chunks.

âœ… **Creates embeddings** using a pretrained model (`HuggingFaceBgeEmbeddings`).

âœ… **Stores the vectors** in a **Chroma vector store** (a type of database for embeddings).

âœ… **Uses a powerful pretrained LLM** (LLaMA 3 via **ChatGroq**) to generate answers.

âœ… **Exposes the QA system** via a **FastAPI endpoint**.

---

## âŒ Does it *train* a model?

No. It does **NOT** train a new machine learning or deep learning model from scratch.

Instead, it does this:

---

## ðŸ§  Pretrained Models Used

- **Embedding model**: `sentence-transformers/all-MiniLM-L6-v2`
- **LLM**: `llama3-70b-8192` (served via **Groq**)

---

## ðŸ§® What It *Does* Do

- **Embeds texts** (vectorizes them) and stores them
- Uses **RetrievalQA**, which performs **retrieval-augmented generation (RAG)**

---

## ðŸ”„ So How Does It *Behave Like Training*?

The only â€œlearning-likeâ€ aspect is:

> Embedding the intents and PDFs into vector space to enable **semantic search**.

This is not full training, but rather a **data preparation + embedding step**.

Embedding the intents and PDFs into vector space to enable semantic search.

This is not full training, but rather a data preparation + embedding step.

