{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-_QYZ_B-qUr",
        "outputId": "140fb83e-67d9-425f-cdb4-6614c556d444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m895.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 1: Install Required Packages\n",
        "!pip install -q langchain langchain-core langchain-community \\\n",
        "    langchain-groq \\\n",
        "    sentence-transformers \\\n",
        "    chromadb \\\n",
        "    pypdf \\\n",
        "    huggingface-hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "import os\n",
        "import json\n",
        "\n",
        "def convert_metadata(metadata):\n",
        "    \"\"\"Convert complex metadata values to strings\"\"\"\n",
        "    new_metadata = {}\n",
        "    for key, value in metadata.items():\n",
        "        if isinstance(value, (list, dict)):\n",
        "            new_metadata[key] = str(value)\n",
        "        else:\n",
        "            new_metadata[key] = value\n",
        "    return new_metadata\n",
        "\n",
        "def load_chatbot_json(file_path):\n",
        "    \"\"\"Loader for chatbot-like intents structure\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        documents = []\n",
        "\n",
        "        if isinstance(data, list):\n",
        "            intents = data\n",
        "        elif isinstance(data, dict) and \"intents\" in data:\n",
        "            intents = data[\"intents\"]\n",
        "        else:\n",
        "            intents = []\n",
        "\n",
        "        for intent in intents:\n",
        "            patterns = intent.get(\"patterns\", [])\n",
        "            responses = intent.get(\"responses\", [])\n",
        "            tag = intent.get(\"tag\", \"no_tag\")\n",
        "\n",
        "            for pattern in patterns:\n",
        "                doc = Document(\n",
        "                    page_content=pattern,\n",
        "                    metadata=convert_metadata({\n",
        "                        \"tag\": tag,\n",
        "                        \"responses\": responses,\n",
        "                        \"source\": \"chatbot_json\"\n",
        "                    })\n",
        "                )\n",
        "                documents.append(doc)\n",
        "        return documents\n",
        "\n",
        "def load_context_response_json(file_path):\n",
        "    \"\"\"Loader for context-response JSON structure\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        documents = []\n",
        "\n",
        "        if isinstance(data, list):\n",
        "            intents = data\n",
        "        else:\n",
        "            intents = []\n",
        "\n",
        "        for intent in intents:\n",
        "            context = intent.get(\"Context\", \"\")\n",
        "            response = intent.get(\"Response\", \"\")\n",
        "\n",
        "            doc = Document(\n",
        "                page_content=context,\n",
        "                metadata=convert_metadata({\n",
        "                    \"response\": response,\n",
        "                    \"source\": \"context_response_json\"\n",
        "                })\n",
        "            )\n",
        "            documents.append(doc)\n",
        "        return documents\n",
        "\n",
        "def load_pdf(file_path):\n",
        "    \"\"\"Loader for PDF files\"\"\"\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = loader.load()\n",
        "    for page in pages:\n",
        "        page.metadata = convert_metadata({\n",
        "            **page.metadata,\n",
        "            \"source\": \"pdf\"\n",
        "        })\n",
        "    return pages\n",
        "\n",
        "def create_vector_db():\n",
        "    directory = \"./sample_data/\"\n",
        "    all_documents = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "\n",
        "        try:\n",
        "            if filename.endswith(\".json\"):\n",
        "                # Try both JSON formats\n",
        "                try:\n",
        "                    docs = load_chatbot_json(file_path)\n",
        "                except:\n",
        "                    docs = load_context_response_json(file_path)\n",
        "                all_documents.extend(docs)\n",
        "\n",
        "            elif filename.endswith(\".pdf\"):\n",
        "                docs = load_pdf(file_path)\n",
        "                all_documents.extend(docs)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {filename}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Filter complex metadata and split documents\n",
        "    filtered_docs = [filter_complex_metadata(doc) for doc in all_documents]\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False\n",
        "    )\n",
        "    texts = text_splitter.split_documents(filtered_docs)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    vector_db = Chroma.from_documents(\n",
        "        documents=texts,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./chroma_db\"\n",
        "    )\n",
        "    vector_db.persist()\n",
        "    print(\"Vector database created with all training data\")\n",
        "    return vector_db\n",
        "\n",
        "def initialize_llm():\n",
        "    llm = ChatGroq(\n",
        "        temperature=0,\n",
        "        groq_api_key=\"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\",\n",
        "        model_name=\"llama3-70b-8192\"\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    You are a compassionate mental health chatbot. Use the following context to respond thoughtfully:\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    User Question: {question}\n",
        "\n",
        "    If the context contains specific responses, you may use them directly when appropriate.\n",
        "    Otherwise, generate a helpful response based on your mental health knowledge.\n",
        "\n",
        "    Chatbot Response:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "def main():\n",
        "    print(\"Initializing Mental Health Chatbot...\")\n",
        "    llm = initialize_llm()\n",
        "    db_path = \"./chroma_db\"\n",
        "\n",
        "    if not os.path.exists(db_path):\n",
        "        os.makedirs(db_path)\n",
        "        vector_db = create_vector_db()\n",
        "    else:\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "    print(\"\\nChatbot ready. Type 'exit' to end the conversation.\")\n",
        "    while True:\n",
        "        query = input(\"\\nUser: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Chatbot: Take care of yourself. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        result = qa_chain({\"query\": query})\n",
        "        response = result[\"result\"]\n",
        "        sources = set(doc.metadata.get(\"source\", \"unknown\") for doc in result[\"source_documents\"])\n",
        "\n",
        "        print(f\"\\nChatbot: {response}\")\n",
        "        print(f\"[Sources: {', '.join(sources)}]\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm0u6_pRBczH",
        "outputId": "d7f1dc93-8e5c-4c59-e212-5da2d9321261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Mental Health Chatbot...\n",
            "\n",
            "Chatbot ready. Type 'exit' to end the conversation.\n",
            "\n",
            "User: I have depression \n",
            "\n",
            "Chatbot: I'm so sorry to hear that you're struggling with depression. It takes a lot of courage to acknowledge and share about your struggles, and I'm here to support you.\n",
            "\n",
            "Firstly, please know that you're not alone in this. Depression is a common mental health condition that affects many people, and it's not a sign of weakness or a personal failing. It's important to remember that depression is a treatable condition, and there is hope for recovery.\n",
            "\n",
            "How have you been experiencing depression lately? What are some of the symptoms you've been struggling with, and how have they been affecting your daily life?\n",
            "\n",
            "Remember, I'm here to listen without judgment, and everything shared with me is confidential. If you're comfortable, can you tell me a bit more about what you're going through?\n",
            "[Sources: ]\n",
            "\n",
            "User: how to  reduce stress\n",
            "\n",
            "Chatbot: Reducing stress is such an important topic! I'm here to help you with that.\n",
            "\n",
            "Firstly, let's acknowledge that stress is a normal part of life, and it's amazing that you're taking steps to manage it. Here are some evidence-based strategies that might help:\n",
            "\n",
            "1. **Deep Breathing Exercises**: When we're stressed, our breathing tends to become shallow and rapid. Consciously taking slow, deep breaths can calm your nervous system. Try inhaling for a count of 4, holding for 7, and exhaling for 8. Repeat this process several times a day.\n",
            "2. **Physical Activity**: Regular exercise can help reduce stress and anxiety by releasing endorphins, also known as \"feel-good\" hormones. Find an activity you enjoy, whether it's walking, jogging, yoga, or dancing, and aim to do it for at least 30 minutes a day.\n",
            "3. **Mindfulness Meditation**: Mindfulness practices can help you focus on the present moment and reduce worries about the past or future. You can start with guided meditations (there are many free apps and videos available) and gradually move to independent practice.\n",
            "4. **Time Management**: Poor time management can lead to increased stress levels. Prioritize your tasks, set realistic goals, and take regular breaks to maintain a healthy work-life balance.\n",
            "5. **Social Connection**: Surrounding yourself with supportive people can help you feel heard, validated, and less stressed. Reach out to a friend, family member, or mental health professional for a chat.\n",
            "6. **Self-Care**: Make time for activities that bring you joy and relaxation, such as reading, listening to music, or taking a warm bath.\n",
            "7. **Get Enough Sleep**: Aim for 7-8 hours of sleep each night to help your body and mind recharge. Establish a consistent sleep schedule and create a relaxing bedtime routine.\n",
            "8. **Healthy Eating**: Focus on consuming a balanced diet rich in whole foods, fruits, and vegetables. Avoid sugary and processed foods that can exacerbate stress.\n",
            "9. **Learn to Say No**: Set healthy boundaries by saying no to commitments that drain your energy and say yes to those that nourish your mind, body, and soul.\n",
            "10. **Seek Professional Help**: If you're experiencing chronic stress that's impacting your daily life, consider seeking help from a mental health professional. They can provide personalized guidance and support.\n",
            "\n",
            "Remember, everyone's journey with stress is unique, and it might take some experimentation to find what works best for you. Be patient, kind, and compassionate with yourself as you explore these strategies.\n",
            "\n",
            "Which of these suggestions resonates with you, or is there something else you'd like to talk about?\n",
            "[Sources: ]\n"
          ]
        }
      ]
    }
  ]
}